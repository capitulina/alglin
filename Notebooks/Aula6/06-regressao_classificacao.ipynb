{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão e Classificação\n",
    "\n",
    "Este capítulo está ligado ao seguintes objetivos didáticos do curos:\n",
    "1. Interpretar e analisar transformações lineares\n",
    "1. Explicar as noções de informação e codificação\n",
    "\n",
    "Referência bibliográfica: [Philip N. Klein - Coding the Matrix - 1st Edition](https://codingthematrix.com/) - Chap. 9.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1\n",
    "\n",
    "## Exercício 1\n",
    "**Objetivo: Visualizar pontos medidos e comparar com uma teoria**\n",
    "\n",
    "Quando observamos a realidade, somos capazes de *medir* coisas. Por exemplo, podemos tentar medir a velocidade do som da seguinte forma: uma pessoa dá um grito ao mesmo tempo em que aciona um cronômetro, e outra pessoa, a alguns metros de distância, pára esse mesmo cronômetro no momento em que ouve o grito. Repetimos o experimento para várias distâncias diferentes e conseguimos, então, uma série de medidas pareadas de tempo e distância.\n",
    "\n",
    "Se fôssemos capazes de acionar o cronômetro exatamente no tempo em que o grito é emitido, e pudéssemos parar o cronômetro exatamente no instante em que o grito é ouvido, então teríamos a seguinte situação:\n",
    "\n",
    "Sabemos que o som se propaga em uma determinada velocidade, que é constante, e portanto o som obedece a um movimento uniforme. Vamos chamar essa velocidade de $c$. Para cada distância $\\Delta s$ teríamos um tempo de propagação igual a $t = \\frac{1}{c} \\Delta s$.\n",
    "\n",
    "Essa ideia de que um fenômeno obedece a uma equação (ou a um modelo, ou a uma \"regra\", ou uma lei) chama-se *teoria*. Então, poderíamos ter resultados *teóricos* que poderiam se parecer com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "c = 300 # velocidade do som, em metros por segundo - esse valor foi absolutamente inventado para fins de exemplo\n",
    "delta_s = np.linspace(60,100,20) # medimos 20 distâncias, indo de 60 a 100 metros\n",
    "t = (1/c) * delta_s\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(delta_s, t)\n",
    "plt.xlabel('Distância (m)')\n",
    "plt.ylabel('Tempo de propagação (s)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porém, na realidade, nossa medição é bastante imperfeita. A primeira fonte dessas imperfeições é que, ao medirmos o tempo de propagação do som, usamos um cronômetro acionado manualmente - então, não somos capazes de acionar o cronômetro *exatamente* no instante em que o som é gerado ou recebido. Outra fonte de erro é que a velocidade do som não é *exatamente* uma constante, porque alterações como ventos e diferenças de temperatura do ar podem afetar a propagação sonora. Também, há fontes de erro que não somos exatamente capazes de prever.\n",
    "\n",
    "Cada um desses erros gera um desvio, e cada um desses desvios tem uma distribuição diferente. Quando somamos todos esses desvios com distribuições diferentes, temos um desvio total com uma distribuição Gaussiana (lembre-se que a Normal, ou Gaussiana, é a distribuição que aparece quando somamos várias contribuições aleatórias de diferentes fontes!) com média zero e desvio padrão que não conhecemos ainda. Então, poderíamos encontrar, de fato, a seguinte situação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "c = 300 # velocidade do som, em metros por segundo - esse valor foi absolutamente inventado para fins de exemplo\n",
    "delta_s = np.linspace(60,100,20) # medimos 20 distâncias, indo de 60 a 100 metros\n",
    "t = (1/c) * delta_s\n",
    "\n",
    "desvio_padrao_da_medicao = 0.01 # Desvio padrão, em segundos - esse número também é inventado!\n",
    "t_medido = t + np.random.randn(20) * desvio_padrao_da_medicao\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(delta_s, t, label='Teoria')\n",
    "plt.scatter(delta_s, t_medido, label='Medição')\n",
    "\n",
    "plt.xlabel('Distância (m)')\n",
    "plt.ylabel('Tempo de propagação (s)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O problema disso tudo é que, geralmente, não conseguimos saber quais são os parâmetros \"reais\" do fenômeno - na verdade, não sabemos nem ao certo que ele obedece a alguma equação. Por isso, precisamos trabalhar com essa suposição sobre como o fenômeno se comporta, e por isso essa suposição é chamada de *teoria*, e não de *realidade*.\n",
    "\n",
    "A palavra *teoria* pode ser entendida como: \"uma ideia que existe dentro na nossa cabeça e que pode ou não corresponder à realidade\". Claro que gostaríamos que nossa teoria se aproximasse mais da nossa realidade - realidade essa que só pode ser acessada à partir das medições. Então, vamos elaborar *hipóteses* sobre o fenômeno e usá-las para encontrar nosso modelo teórico.\n",
    "\n",
    "Usando o código abaixo, discuta:\n",
    "\n",
    "a) Apenas olhando a figura, é possível decidir qual das hipóteses é a que melhor explica os pontos que foram medidos? O que significa \"explicar melhor\"?\n",
    "\n",
    "b) Quando aumentamos o `desvio_padrao_da_medicao`, fica mais fácil ou mais difícil decidir por uma hipótese?\n",
    "\n",
    "c) Quando diminuimos o `desvio_padrao_da_medicao`, fica mais fácil ou mais difícil decidir por uma hipótese?\n",
    "\n",
    "d) Quando aumentamos o número de pontos medidos, fica mais fácil ou mais difícil decidir por uma hipótese?\n",
    "\n",
    "e) Quando diminuímos o número de pontos medidos, fica mais fácil ou mais difícil decidir por uma hipótese?\n",
    "\n",
    "f) Se as hipóteses forem muito próximas umas das outras, é mais fácil ou mais difícil escolher uma delas?\n",
    "\n",
    "g) Se as hipóteses forem muito próximas umas das outras, é mais relevante ou menos relevante escolher exatamente a hipótese correta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "c = 300 # velocidade do som, em metros por segundo - esse valor foi absolutamente inventado para fins de exemplo\n",
    "delta_s = np.linspace(60,100,20) # medimos 20 distâncias, indo de 60 a 100 metros\n",
    "t = (1/c) * delta_s\n",
    "\n",
    "desvio_padrao_da_medicao = 0.01 # Desvio padrão, em segundos - esse número também é inventado!\n",
    "t_medido = t + np.random.randn(20) * desvio_padrao_da_medicao\n",
    "\n",
    "d = 10\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.scatter(delta_s, t_medido, label='Medições')\n",
    "plt.plot(delta_s, (1/(300-2*d)) * delta_s, 'r', label='Hipóteses')\n",
    "plt.plot(delta_s, (1/(300-d)) * delta_s, 'r')\n",
    "plt.plot(delta_s, (1/(300)) * delta_s, 'r')\n",
    "plt.plot(delta_s, (1/(300+d)) * delta_s, 'r')\n",
    "plt.plot(delta_s, (1/(300+2*d)) * delta_s, 'r')\n",
    "plt.xlabel('Distância (m)')\n",
    "plt.ylabel('Tempo de propagação (s)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2\n",
    "*Objetivo: encontrar e analisar o erro de aproximação entre modelo e medidas*\n",
    "\n",
    "Uma característica dos modelos teóricos é que eles existem somente no mundo das abstrações. É claro que, se quisermos usar nosso modelo teórico para fazer algum tipo de predição, então precisamos de um modelo teórico que se aproxime da realidade. Em outras palavras, ao compararmos dois modelos teóricos, como nas curvas abaixo, gostaríamos de escolher o modelo da curva azul, e não o da curva vermelha:\n",
    "\n",
    "<img src=\"teoria_boa_vs_nao_boa.png\" />\n",
    "\n",
    "Claro que não podemos usar o critério de \"olho\" ou \"intuição\" para fazer essa escolha (até podemos no sentido de capacidade, ou mesmo de legalidade, mas com certeza não deveríamos). Ao invés disso, queremo usar um critério objetivo, isto é, encontrar um número que nos diga o quão bom é um modelo. Uma das propostas mais comuns para isso é o **erro quadrático médio**, ou EQM, que funciona da seguinte forma:\n",
    "\n",
    "    Para cada ponto medido (x,y), com o modelo y_est=a*x_medido+b:\n",
    "        estime o valor fornecido pelo modelo y_est = a*x_medido + b\n",
    "        calcule o erro quadrático EQ = (y_est-y_medido)**2\n",
    "    \n",
    "    Após:\n",
    "        calcule o EQM como a média de todos os EQs\n",
    "\n",
    "Outra maneira de entender o EQM é como uma equação:\n",
    "\n",
    "$$\n",
    "\\text{EQM} = \\frac{1}{N} \\sum_{n=1}^N (y_n - (ax_n + b))^2\n",
    "$$\n",
    "\n",
    "Nesta atividade, vamos analisar como o EQM se comporta quando variamos os coeficientes do modelo.\n",
    "\n",
    "1. No código abaixo, complete a função `EQM` para que ela calcule o EQM de um modelo linear frente a medições recebidas como entrada.\n",
    "1. Na figura que é gerada, qual é o coeficiente angular teórico que leva ao menor EQM? Como ele se compara com o EQM teórico?\n",
    "1. Aumente o `desvio_padrao_da_medicao`. Como isso afeta o valor mínimo do EQM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eqm( parametros ):\n",
    "    medidas_x, medidas_y, coef_angular_modelo, coef_linear_modelo = parametros\n",
    "    # Complete esta função\n",
    "\n",
    "    return 0\n",
    "\n",
    "# Gerando a medição\n",
    "medidas_x = np.linspace(10,30,5)\n",
    "coef_linear_real = 0\n",
    "coef_angular_real = 1.7\n",
    "desvio_padrao_da_medicao = 0.1 # Desvio padrão, em segundos - esse número também é inventado!\n",
    "medidas_y = coef_linear_real + coef_angular_real * medidas_x + np.random.randn(len(medidas_x)) * desvio_padrao_da_medicao\n",
    "\n",
    "# Gerando o modelo\n",
    "coef_linear_modelo = 0\n",
    "coef_angular_modelo = 1.8\n",
    "\n",
    "# Candidatos\n",
    "candidatos_coef_angular = np.linspace(0,3,1000)\n",
    "eqms = []\n",
    "for idx, a_ in enumerate(candidatos_coef_angular):\n",
    "    erro_quadratico_medio = eqm( (medidas_x, medidas_y, a_, coef_linear_modelo) )\n",
    "    eqms.append(erro_quadratico_medio)\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(candidatos_coef_angular, eqms)\n",
    "plt.xlabel('Coeficiente angular do modelo')\n",
    "plt.ylabel('EQM')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3\n",
    "*Objetivo: Calcular a derivada do erro em relação aos parâmetros da reta*\n",
    "\n",
    "Em várias aplicações, sabemos de antemão que o coeficiente linear do modelo é zero. Isso significa que o erro do modelo é simplesmente:\n",
    "\n",
    "$$\n",
    "\\text{EQM} = \\frac{1}{N} \\sum_{n=1}^N (y_n - a x_n)^2 = \\frac{1}{N} \\sum_{n=1}^N y_n^2 - 2 a x_n y_n + a^2 x_n^2\n",
    "$$\n",
    "\n",
    "1. Calcule a derivada de EQM em relação ao coeficiente angular $a$, isto é, calcule (no papel) $e'(a) = \\frac{d\\text{EQM}}{da}$. DICA: calcule a derivada para um único ponto (por exemplo, $n=1$), e então some as derivadas para todos os pontos.\n",
    "1. Implemente o cálculo de $e'(a)$ na função abaixo. Quais são os valores de $e'(a)$ quando $a$ (o coeficiente angular do modelo) é muito superior ao coeficiente angular \"real\"? E se $a$ é inferior ao coeficiente angular \"real\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def deqm_da(medidas_x, medidas_y, coef_angular_tentativa):\n",
    "    # Complete esta função\n",
    "\n",
    "    return 0\n",
    "\n",
    "# Gerando a medição\n",
    "medidas_x = np.linspace(10,30,5)\n",
    "coef_angular_teorico = 1.7\n",
    "desvio_padrao_da_medicao = 0.1 # Desvio padrão, em segundos - esse número também é inventado!\n",
    "medidas_y = coef_angular_teorico * medidas_x + np.random.randn(len(medidas_x)) * desvio_padrao_da_medicao\n",
    "\n",
    "# Gerando o modelo\n",
    "coef_angular_modelo = 1.8\n",
    "\n",
    "# Candidatos\n",
    "candidatos_coef_angular = np.linspace(0,3,1000)\n",
    "eqms = []\n",
    "for idx, a_ in enumerate(candidatos_coef_angular):\n",
    "    erro_quadratico_medio = deqm_da(medidas_x, medidas_y, a_)\n",
    "    eqms.append(erro_quadratico_medio)\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(candidatos_coef_angular, eqms)\n",
    "plt.xlabel('a')\n",
    "plt.ylabel(\"e'(a)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 4\n",
    "*Objetivo: entender o processo de descida pelo gradiente*\n",
    "\n",
    "Partindo de um modelo linear com coeficiente angular $a$, podemos estimar um novo modelo usando:\n",
    "\n",
    "$a_{\\text{novo}} = a_{\\text{atual}} + \\alpha e'(a)$, onde $\\alpha$ é um valor pequeno e positivo como $0.01$.\n",
    "\n",
    "1. O modelo com coeficiente linear $a_{\\text{novo}}$ deve ter EQM maior ou menor que o modelo com $a_{\\text{atual}}$?\n",
    "1. Como poderíamos mudar o procedimento de estimativa de forma que o modelo novo tenha EQM menor que o modelo antigo?\n",
    "1. Usando as funções que você já implementou, complete a função `melhorar_modelo` no código abaixo de forma a implementar o cálculo de um $a_{\\text{novo}}$.\n",
    "1. Aplicando sucessivamente a função melhorar_modelo, verifique se você consegue aproximar o coeficiente angular teórico dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melhorar_modelo(medidas_x, medidas_y, alpha, a_atual):\n",
    "    a_novo = a_atual * 0.9 #Modifique isso \n",
    "    return a_novo\n",
    "\n",
    "# Gerando a medição\n",
    "medidas_x = np.linspace(10,30,5)\n",
    "coef_angular_teorico = 1.7\n",
    "desvio_padrao_da_medicao = 0.5 # Desvio padrão\n",
    "medidas_y = coef_angular_teorico * medidas_x + np.random.randn(len(medidas_x)) * desvio_padrao_da_medicao\n",
    "\n",
    "# Buscar sucessivamente por coeficientes angulares\n",
    "a_ = 5.0 # Esse é o coeficiente angular tentativa\n",
    "alpha = 0.1\n",
    "for _ in range(100):\n",
    "    a_ = melhorar_modelo(medidas_x, medidas_y, alpha, a_)\n",
    "\n",
    "print(\"Coeficiente angular encontrado:\", a_)\n",
    "print(\"Coeficiente angular real:\", coef_angular_teorico)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 5\n",
    "*Objetivo: estimar um coeficiente angular em dados reais*\n",
    "\n",
    "Neste experimento, estimaremos a aceleração da gravidade ($g$). O experimento funciona da seguinte forma:\n",
    "\n",
    "* Sabemos que o tempo de queda $t$ de um objeto que cai de uma altura $h$ é dado por $t=\\sqrt{\\frac{2h}{g}}$.\n",
    "* Isso significa que $t^2 = \\frac{2}{g} h$\n",
    "* Então, se assumirmos que $y=t^2$ e $x=h$, podemos encontrar uma reta $y=ax$ onde $a=\\frac{2}{g}$.\n",
    "\n",
    "O procedimento experimental, portanto, é:\n",
    "\n",
    "1. Escolha um objeto que pode ser jogado sem quebrar (por exemplo, uma borracha).\n",
    "1. Solte o objeto de uma altura conhecida $h$ e meça o tempo de queda $t$ usando um cronômetro (pode ser, por exemplo, o cronômetro do celular)\n",
    "1. Anote a altura e o tempo de queda.\n",
    "1. Repita o procedimento até juntar algumas dezenas de pontos. Compartilhe suas medições com o restante da turma!!!\n",
    "1. Calcule $y=t^2$ para todos os seus pontos\n",
    "1. Use o procedimento que fizemos no exercício anterior para estimar o valor do coeficiente $a$ no modelo linear\n",
    "1. À partir do coeficiente $a$, calcule o valor da aceleração da gravidade usando $a=\\frac{2}{g}$.\n",
    "\n",
    "Quanto vale a aceleração da gravidade $g$ na sua sala de aula?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 6\n",
    "**Objetivo: Encontrar a derivada de uma função**\n",
    "\n",
    "Até o momento, estamos encontrando os parâmetros do nosso modelo dando pequenos passos na direção contrária à derivada do erro em relação ao parâmetro, isto é, a n-ésima iteração do parâmetro $a$ é encontrada usando:\n",
    "\n",
    "$$\n",
    "a_n = a_{n-1} - \\alpha \\frac{dE}{da},\n",
    "$$\n",
    "\n",
    "onde $E$ é o erro que calculamos (por exemplo o EQM) e $\\alpha$ é um número real bem pequeno.\n",
    "\n",
    "Podemos calcular a derivada do erro em relação a todos os parâmetros do nosso modelo, mas é claro que em modelos mais complicados o cálculo desse gradiente vai ficando cada vez mais difícil. Por isso, podemos usar o pacote `autograd`, que calcula automaticamente o gradiente de uma função chamada `loss` em relação aos parâmetros livres de um modelo. Se você quiser saber mais sobre como o autograd funciona, uma boa ideia é começar na própria [página web do autograd](https://github.com/HIPS/autograd/blob/master/docs/tutorial.md).\n",
    "\n",
    "Neste exercício, verificaremos que o autograd, de fato, funciona, e como é sua mecânica, usando uma função polinomial.\n",
    "\n",
    "1. No código abaixo, identifique qual é o polinômio $p(x)$ que está sendo calculado. Quais são os *coeficientes* do polinômio?\n",
    "1. Calcule manualmente a derivada do polinômio em relação a x, e complete a função `derivada`\n",
    "1. Teste sua função `derivada` em alguns pontos e verifique que ela está correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polinomio( parametros ):\n",
    "    x, a0, a1, a2 = parametros\n",
    "    px = a0 + a1*x + a2*x**2.0\n",
    "    return px\n",
    "\n",
    "def derivada( parametros ):\n",
    "    x, a0, a1, a2 = parametros\n",
    "    return 0\n",
    "\n",
    "a0 = 1.\n",
    "a1 = 0.\n",
    "a2 = 2.\n",
    "poli = []\n",
    "deri = []\n",
    "x_ = []\n",
    "for x in np.linspace(-2, 2, 17):\n",
    "    x_.append(x)\n",
    "    poli.append(polinomio ( (x, a0, a1, a2) ))\n",
    "    deri.append(derivada ( (x, a0, a1, a2) ))\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(x_, poli, label='Polinômio')\n",
    "plt.plot(x_, deri, label='Derivada')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 7\n",
    "**Objetivo: usar autograd para encontrar a derivada de uma função**\n",
    "\n",
    "Embora calcular derivadas de polinômios seja um caso relativamente simples (quando comparado a outras derivadas), é comum que desejemos calcular derivadas de funções mais complicadas, ou simplesmente que náo queiramos nos preocupar com a derivada de uma função. Para isso, usamos o pacote `autograd`. A função que usaremos é a função `grad`.\n",
    "\n",
    "Veja no código abaixo como a função `grad` funciona. Usando essas ideias, faça uma função `derivada_do_polinomio` que calcula a derivada do polinômio que você encontrou no exercício anterior, e verifique como ela fornece as mesmas informações que a função `derivada` que você já fez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np_\n",
    "from autograd import grad\n",
    "\n",
    "def funcao_que_quero_derivar ( parametros_como_tupla ):\n",
    "    parametro1, parametro2 = parametros_como_tupla\n",
    "    return parametro1 + parametro2**3 + 1\n",
    "\n",
    "derivada_por_autograd = grad(funcao_que_quero_derivar)\n",
    "\n",
    "derivada1, derivada2 = derivada_por_autograd( (1., 2.) ) # Veja como passei os parametros como uma tupla!\n",
    "print(derivada1, derivada2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polinomio( parametros ):\n",
    "    x, a0, a1, a2 = parametros\n",
    "    px = a0 + a1*x + a2*x**2.0\n",
    "    return px\n",
    "\n",
    "derivada_por_autograd = grad(polinomio)\n",
    "\n",
    "a0 = 1.\n",
    "a1 = 0.\n",
    "a2 = 2.\n",
    "poli = []\n",
    "deri = []\n",
    "x_ = []\n",
    "for x in np.linspace(-2, 2, 17):\n",
    "    x_.append(x)\n",
    "    poli.append(polinomio ( (x, a0, a1, a2) ))\n",
    "    deri.append(derivada_por_autograd ( (x, a0, a1, a2) )[0])\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(x_, poli, label='Polinômio')\n",
    "plt.plot(x_, deri, label='Derivada')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 8\n",
    "**Objetivo: usar autograd para minimizar o EQM de uma aproximação**\n",
    "\n",
    "Usando o procedimento de calcular a derivada do erro em relação a cada um dos parâmetros do modelo, use `autograd` para minimizar o EQM da aproximação $y=ax+b$ para os dados medidos abaixo. Os parâmetros $a$ e $b$ do modelo se aproximam dos \"reais\", que foram usados para gerar os dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados \"reais\"\n",
    "a_real = 4\n",
    "b_real = 10\n",
    "x = np.random.random(100) * 100\n",
    "x = np.sort(x)\n",
    "y = a_real * x + b_real\n",
    "\n",
    "# Dados \"medidos\"\n",
    "ym = y + np.random.randn(y.shape[0])*250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np_\n",
    "from autograd import grad\n",
    "\n",
    "def erro( parametros ):\n",
    "    a, b, x, y_medido = parametros\n",
    "    yhat = a * x + b\n",
    "    mse = 0 # modifique esta linha!!\n",
    "    return mse\n",
    "\n",
    "g = grad(erro)\n",
    "\n",
    "a_modelo, b_modelo = 0.0, 0.0\n",
    "alpha = 0.0001\n",
    "for _ in range(100): # por 10 iterações...\n",
    "    pass\n",
    "    # Calcular gradiente\n",
    "\n",
    "    # Modificar parametros do modelo para reduzir o erro\n",
    "\n",
    "print(a_modelo, b_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados \"medidos\"\n",
    "y_modelo = a_modelo * x + b_modelo\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(x, y, 'r', label='Real')\n",
    "plt.plot(x, y_modelo, 'y', label='Modelo')\n",
    "plt.scatter(x, ym, label='Medido')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 9\n",
    "**Objetivo: usar autograd para realizar um experimento científico**\n",
    "\n",
    "Usando os dados que você já tem do tempo de queda de objetos, re-faça o experimento de descobrir a gravidade usando `autograd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np_\n",
    "from autograd import grad\n",
    "\n",
    "# Faça seu código aqui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 10\n",
    "*Objetivo: entender o problema de classificação linear*\n",
    "\n",
    "Podemos calcular um valor para cada ponto em um plano cartesiano fazendo uma função. Por exemplo, podemos dizer que o ponto $(x,y)$ tem um \"valor\" $f(x,y) = x+y$. Uma possibilidade para esse tipo de função é que ela seja uma função linear, ou seja:\n",
    "\n",
    "$$\n",
    "f(x,y) = Ax + By + C\n",
    "$$\n",
    "\n",
    "Nos pontos em que $f(x,y)=0$, encontramos que $Ax + By + C=0$, que é a equação de uma reta.\n",
    "\n",
    "O código abaixo mostra como isso divide o plano entre o lado \"positivo\" e o \"negativo\".\n",
    "\n",
    "1. Adicione ao *plot* o desenho da reta $Ax+By+C$ que realiza a divisão dos lados positivo e negativo.\n",
    "1. Se as variáveis $x$ e $y$ representam a altura e o peso de personagens (em alguma unidade imaginária em que nossos números fazem sentido), e queremos identificar elfos e anões do Senhor dos Anéis, relacione os grupos (azul e vermelho) a suas categorias (elfos ou anões)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "A = 1.0\n",
    "B = -1.0\n",
    "C = -0.5\n",
    "\n",
    "pontos = np.random.random( (2,500) )*20+.5\n",
    "funcao = A*pontos[0,:] + B*pontos[1,:] + C\n",
    "\n",
    "pontos_pos = pontos[:, funcao > 0]\n",
    "pontos_neg = pontos[:, funcao < 0]\n",
    "print(pontos_pos.shape, pontos_neg.shape)\n",
    "plt.figure()\n",
    "plt.scatter(pontos_pos[0,:], pontos_pos[1,:], c='b')\n",
    "plt.scatter(pontos_neg[0,:], pontos_neg[1,:], c='r')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 11\n",
    "**Objetivo: Usar autograd para modelar sistema de classificação usando EQM**\n",
    "\n",
    "Veja que agora fizemos um classificador cujos parâmetros são $A$, $B$ e $C$, e cujas entradas são $x$ e $y$. Em situações reais, raramente sabemos os parâmetros $A$, $B$ e $C$, e gostaríamos de identificá-los através de dados. Para isso, vamos usar a estratégia de descida pelo gradiente, assim como temos feito para o problema de regressão.\n",
    "\n",
    "Gostaríamos de estimar uma função $f(x,y) = Ax+By+C$ de tal forma que $f(x_p,y_p)=1$ se $(x_p,y_p)$ for um ponto da categoria (ou classe) 1, e  $f(x_p,y_p)=-1$ se $(x_p,y_p)$ caso os pontos sejam da categoria 2.\n",
    "\n",
    "O erro do nosso modelo é o EQM que relaciona $f(x,y)$ estimado pelo nosso modelo com os valores desejados 1 e -1.\n",
    "\n",
    "1. Usando o que já fizemos, use o `autograd` para estimar o modelo $f(x,y) = Ax+By+C$ à partir dos dados abaixo.\n",
    "1. Faça um plot semelhante ao do exercício 6 mostrando os pontos de cada categoria de dados com uma cor diferente e a reta estimada.\n",
    "1. Modifique o valor da contante `SEP` para que tenha valores menores e valores maiores. O que acontece com o modelo estimado?\n",
    "1. Modifique seu código para que ele passe a ter muito mais elementos da categoria 1 que elementos da categoria 2. O que acontece com o modelo estimado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEP =3\n",
    "\n",
    "dados_c1 = np.random.randn(2,50) + SEP\n",
    "dados_c2 = np.random.randn(2,50) - SEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np_   # Thinly-wrapped version of Numpy\n",
    "from autograd import grad\n",
    "\n",
    "def loss( parametros ):\n",
    "    A, B, C, pontos, val = parametros\n",
    "    est = A*pontos[0,:] + B*pontos[1,:] + C\n",
    "    mse = np_.mean( (est - val)**2)\n",
    "    return mse\n",
    "\n",
    "g = grad(loss)\n",
    "\n",
    "pontos = np.hstack ( (dados_c1, dados_c2))\n",
    "alvos = np.hstack ( (np.ones(50), -1*np.ones(50)))\n",
    "\n",
    "A, B, C = 0.0, 0.1, 0.2\n",
    "alpha = 10**-2\n",
    "\n",
    "for n in range(100):\n",
    "    grad_ = g( (A, B, C, pontos, alvos) )\n",
    "    A -= alpha*grad_[0]\n",
    "    B -= alpha*grad_[1]\n",
    "    C -= alpha*grad_[2]\n",
    "\n",
    "\n",
    "funcao = A*pontos[0,:] + B*pontos[1,:] + C\n",
    "\n",
    "# Reta:\n",
    "# y = -A/B x + C/B\n",
    "x = np.linspace(-3,3,100)\n",
    "y = -A*x/B - C/B\n",
    "\n",
    "pontos_pos = pontos[:, funcao > 0]\n",
    "pontos_neg = pontos[:, funcao < 0]\n",
    "print(pontos_pos.shape, pontos_neg.shape)\n",
    "plt.figure(figsize=(11,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Dados originais')\n",
    "plt.scatter(dados_c1[0,:], dados_c1[1,:], c='b')\n",
    "plt.scatter(dados_c2[0,:], dados_c2[1,:], c='r')\n",
    "plt.plot(x, y)\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Dados classificados')\n",
    "plt.scatter(pontos_pos[0,:], pontos_pos[1,:], c='b')\n",
    "plt.scatter(pontos_neg[0,:], pontos_neg[1,:], c='r')\n",
    "plt.plot(x, y)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 12\n",
    "**Objetivo: fazer uma formulação matricial para o classificador linear**\n",
    "\n",
    "Até o momento, a função que executamos para o classificador linear é:\n",
    "\n",
    "$$\n",
    "f(x,y) = Ax + By + C\n",
    "$$\n",
    "\n",
    "Nessa formulação, estamos assumindo que nossa entrada tem duas dimensões ($x$ e $y$).\n",
    "\n",
    "Veja como $f(x,y)$ funciona como se $A$ é o \"peso\" atribuído a $x$, e $B$ é o \"peso\" atribuído a $y$. $C$ é uma variável que nos dá uma tendência que é independente das entradas.\n",
    "\n",
    "Essa interpretação funciona para pontos em $2$ dimensões. Se quisermos, podemos assumir que nossa entrada tem $N$ dimensões, expressas em um vetor-coluna $\\boldsymbol x$. Nesse caso, os coeficientes do nosso classificador devem ser colocados também em um vetor-coluna $\\boldsymbol w$, e então ficamos com:\n",
    "\n",
    "$$\n",
    "f(\\boldsymbol x) = b + \\sum_n w_n x_n = \\begin{bmatrix} w_0 & w_1 & ... & w_{N-1} \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ ... \\\\ x_{N-1} \\end{bmatrix} + b = \\boldsymbol w^T \\boldsymbol x + b\n",
    "$$\n",
    "\n",
    "Usando uma formulação matricial, faça um classificador linear para separar os dados abaixo. Quais são os pesos $\\boldsymbol w$ do classificador que você encontrou?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEP = 10\n",
    "N_DIMENSOES = 5\n",
    "N_DADOS = 500\n",
    "\n",
    "dados_c1 = np.random.randn(N_DIMENSOES,N_DADOS) + SEP\n",
    "dados_c2 = np.random.randn(N_DIMENSOES,N_DADOS) - SEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np_   # Thinly-wrapped version of Numpy\n",
    "from autograd import grad\n",
    "\n",
    "def loss( parametros ):\n",
    "    w, b, pontos, val = parametros\n",
    "    est = w.T @ pontos + b\n",
    "    mse = np_.mean( (est - val)**2)\n",
    "    return mse\n",
    "\n",
    "g = grad(loss)\n",
    "\n",
    "pontos = np.hstack ( (dados_c1, dados_c2))\n",
    "alvos = np.hstack ( (np.ones(N_DADOS), -1*np.ones(N_DADOS)))\n",
    "\n",
    "w = np.random.randn( N_DIMENSOES,1)\n",
    "b = 0.0\n",
    "alpha = 10**-3\n",
    "\n",
    "for n in range(1000):\n",
    "    grad_ = g( (w, b, pontos, alvos) )\n",
    "    w -= alpha*grad_[0]\n",
    "    b -= alpha*grad_[1]\n",
    "\n",
    "print(w)\n",
    "print(b)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 13\n",
    "**Objetivo: avaliar o classificador**\n",
    "\n",
    "Neste momento, já somos capazes de encontrar os pesos $\\boldsymbol w$ e o *bias* $b$ do nosso classificador. Porém: ele funciona bem, na prática?\n",
    "\n",
    "Para saber disso, precisamos de dois conjuntos de dados. Um deles, chamado *conjunto de treino*, será usado para encontrar os pesos do classificador. O outro, chamado *conjunto de teste*, será usado para avaliar se o classificador funciona bem em dados que ele ainda não encontrou. Ambos os conjuntos têm pares de entradas e saídas.\n",
    "\n",
    "Neste exercício, começaremos com dados que já foram pré-processados. Eles foram extraídos do [breast cancer dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)), e já estão organizados para que as entradas e saídas correspondam ao que fizemos nesta aula.\n",
    "\n",
    "1. Verifique as dimensões dos dados no conjunto de treino e no conjunto de teste.\n",
    "1. Inicialize uma vetor de pesos e um *bias* para a classificação.\n",
    "1. Com as inicializações aleatórias, execute o classificador no conjunto de teste e verifique o accuracy.\n",
    "1. Ajuste o vetor de pesos e o *bias* através de reduzir o erro de classificação para o conjunto de *treino*. Ajuste a taxa de aprendizado $\\alpha$ e o número de iterações que serão realizadas.\n",
    "1. Com os pesos e *bias* ajustados, execute o classificador no conjunto de teste e verifique o accuracy. O treino foi efetivo?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "X_train, X_test, y_train, y_test = joblib.load('./dados_classificacao.joblib')\n",
    "\n",
    "def accuracy(y_test, y_est):\n",
    "    return np.mean(np.sign(y_test)==np.sign(y_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolva o exercício aqui\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4\n",
    "\n",
    "## Exercício 14\n",
    "*Objetivo: entender o que são decisões binárias em sequência*\n",
    "\n",
    "Vamos jogar um jogo de adivinhações usando um baralho comum, com quatro naipes e 13 cartas por naipe (de \"ás\" a 10, e, adicionalmente, Q, J, K).\n",
    "\n",
    "Neste jogo, teremos dois jogadores. \n",
    "\n",
    "* O jogador 1 deve escolher uma das cartas e manter sua escolha em segredo. \n",
    "* Em seguida, o jogador 2 deve fazer perguntas para tentar adivinhar qual carta foi escolhida.\n",
    "* As perguntas devem ter resposta \"sim\" ou \"não\". Exemplos de perguntas válidas são:\n",
    "    * A carta é um número?\n",
    "    * A carta é um número ímpar?\n",
    "    * A carta é do naipe \"espadas\"?\n",
    "    * A carta é de um naipe preto ou vermelho?\n",
    "    * A carta é uma figura?\n",
    "    * A carta é uma \"dama\"?\n",
    "    * A carta é uma dama de copas?\n",
    "* Não é permitido perguntar se a carta é \"maior que\" outra carta!\n",
    "* O objetivo do jogador 2 é conseguir encontrar a carta com o mínimo de perguntas.\n",
    "* O objetivo do jogador 1 é conseguir escolher a carta que é obriga o jogador 2 a fazer o máximo de perguntas antes de encontrar a carta.\n",
    "\n",
    "## Exercício 15\n",
    "*Objetivo: comparar duas estratégias para o jogo de adivinhações*\n",
    "\n",
    "Uma estratégia direta para o jogo de adivinhações é simplesmente fazer uma lista de todas as cartas e então perguntar sobre elas, uma por uma: \"é um ás de espadas? é um dois de espadas?\", etc.\n",
    "\n",
    "Uma outra estratégia é a de escolher perguntas que, independente da resposta, eliminam o maior número de possibilidades: \"é uma carta vermelha?\", \"é uma carta de espadas?\", \"é um número ímpar?\", e assim por diante.\n",
    "\n",
    "1. Desenhe *árvores binárias* mostrando como as decisões são progressivamente aplicadas para escolher as cartas.\n",
    "1. Analisando a árvore de cada, responda: qual dessas duas estratégias mais provavelmente leva a encontrar a carta com o mínimo de perguntas? \n",
    "1. Qual característica da árvore binária está ligada ao número de perguntas necessário para encontrar a carta?\n",
    "\n",
    "\n",
    "## Exercício 16\n",
    "*Objetivo: entender o que é entropia de Shannon e sua relação com o jogo de adivinhação*\n",
    "\n",
    "Uma possível maneira de definir o \"poder de decisão\" de uma pergunta é usar a Entropia de Shannnon. A entropia é um conceito ligado à quantidade de informação de uma decisão ou de uma resposta, e foi refinada por [Shannon (1948)](https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf). Não vamos deduzir os *motivos* que levam à formulação proposta por Shannon, mas, se você quiser, pode ler o artigo original - ele é difícil, porém muito claro.\n",
    "\n",
    "A Entropia de Shannon é um valor $H(X)$ ligado a uma variável aleatória $X$. No caso discreto (que é o que nos interessa), a entropia é a soma de $- P(X=x_i) \\log_2(P(X=x_i))$ para cada observação possível $x_i$, ou:\n",
    "\n",
    "$$\n",
    "H(X) = -\\sum_i P(X=x_i) \\log _2(P(X=x_i)).\n",
    "$$\n",
    "\n",
    "Uma formulação que é muito comum encontrar em livros é substituir $P(X=x_i)$ por $p(x_i)$, encontrando:\n",
    "\n",
    "$$\n",
    "H(X) = -\\sum_i p(x_i) \\log _2(p(x_i)).\n",
    "$$\n",
    "\n",
    "A Entropia de Shannon é medida em *bits* (ao longo das próximas aulas vamos entender melhor o motivo disso).\n",
    "\n",
    "**EXEMPLO**\n",
    "\n",
    "Se tivermos uma moeda honesta, temos uma variável aleatória $X$ com p(CARA)=0.5 e p(COROA)=0.5. Então, a Entropia de Shannon da moeda é:\n",
    "\n",
    "$$\n",
    "H(X) = - (0.5 \\log _2(0.5) + 0.5 \\log _2(0.5)) \n",
    "$$\n",
    "\n",
    "Como $\\log _2(0.5)=-1$, então:\n",
    "\n",
    "$$\n",
    "H(X) = - (-0.5 + (-0.5)) = - (-1) = 1 \n",
    "$$\n",
    "\n",
    "**EXEMPLO 2**\n",
    "\n",
    "Se tivermos uma moeda desonesta, com p(CARA)=0.7 e p(COROA)=0.3, então temos uma Entropia de Shannon igual a:\n",
    "\n",
    "$$\n",
    "H(X) = - (0.3 \\log _2(0.3) + 0.7 \\log _2(0.7)) \n",
    "$$\n",
    "\n",
    "Como $\\log _2(0.3)$ é um número mais difícil de calcular, vamos recorrer ao recurso computacional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "print(stats.entropy([0.3, 0.7], base=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso significa que, ao jogar uma moeda completamente honesta, ganhamos 1 bit de informação, ao passo que, se a moeda for enviesada (com o viés 0.3-0.7), ganhamos somente 0.88 bit de informação.\n",
    "\n",
    "No limite do viés da moeda, temos uma moeda que sempre dá cara. Nesse caso, temos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "print(stats.entropy([0, 1], base=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isto é, jogar uma moeda que sabemos que sempre dá cara (ou que sempre dá coroa) não nos fornece nenhuma informação nova sobre o sistema.\n",
    "\n",
    "Usando a função `stats.entropy`, sem se esquecer de usar `base=2`:\n",
    "\n",
    "1. Encontre a entropia relacionada a jogar uma moeda enviesada com P(CARA) = 0.9.\n",
    "1. No jogo de cartas, *fazer uma pergunta*, sob o ponto de vista do jogador que pergunta, pode ser entendida como *jogar uma moeda*, com probabilidade de \"sim\" e probabilidade de \"não\". Para a pergunta: *a carta é de um naipe vermelho?*, qual é P(sim) e qual é P(não)?\n",
    "1. Qual é a entropia relacionada à pergunta: *a carta é de um naipe vermelho*?\n",
    "1. Qual é a entropia relacionada à pergunta: *a carta é um rei de copas*?\n",
    "1. Como a entropia se relaciona à \"utilidade\" de uma pergunta para nosso jogo de adivinhações?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 17\n",
    "*Objetivo: usar a entropia para otimizar a estratégia do jogo de adivinhações*\n",
    "\n",
    "Vamos organizar nossas perguntas da seguinte forma:\n",
    "\n",
    "1. Sabemos todas as cartas que podem ser candidatas à escolha. São $N$ cartas (começamos com $N=52$)\n",
    "1. Para cada pergunta que podemos fazer, calculamos sua entropia.\n",
    "1. Escolhemos a pergunta usando aquela que dá a máxima entropia.\n",
    "1. Para a possibilidade da resposta ter sido SIM, temos $N \\times P(SIM)$ cartas. Para a possibilidade da resposta ter sido NAO, temos $N \\times P(NAO)$ cartas.\n",
    "1. Após termos nossa resposta, refazemos a estratégia, agora considerando apenas as cartas que restaram.\n",
    "\n",
    "Usando esta estratégia, tente jogar o jogo novamente. Quantas perguntas você conseguiu fazer?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 18\n",
    "*Objetivo: usar uma árvore de decisão*\n",
    "\n",
    "Veja que as decisões que tomamos em nosso jogo de adivinhações estão organizadas em uma árvore. Por isso, esse tipo de algoritmo é chamado de \"árvore de decisão\". No exemplo abaixo, vamos usar uma árvore de decisão para adivinhar números de 1 a 10 à partir das características:\n",
    "\n",
    "* é um número primo?\n",
    "* é divisível por 2? por 3? por 5? por 7?\n",
    "* o número faz parte da [sequência de fibonacci](https://pt.wikipedia.org/wiki/Sequ%C3%AAncia_de_Fibonacci)?\n",
    "\n",
    "Acompanhe o código passo a passo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Primeiro, vamos ler nossos dados e colocar o rótulo (ou: o número em si) em uma variável,\n",
    "# e as suas características em outra variável:\n",
    "df = pd.read_excel('numeros.xlsx')\n",
    "#print(df.head())\n",
    "df_rotulo = df['número']\n",
    "df_features = df[ ['primo', 'fibo', 'div2', 'div3', 'div5', 'div7'] ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depois, vamos instanciar uma árvore de decisão usando o pacote sklearn:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Agora, vamos usar o método .fit() para ajustar os parâmetros da árvore:\n",
    "tree.fit(df_features, df_rotulo)\n",
    "\n",
    "# Podemos visualizar a árvore de decisão em uma figura!\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure( figsize=(20,20) )\n",
    "a = plot_tree(tree, feature_names=df_features.columns, fontsize=15, \n",
    "              node_ids=False, impurity=False, filled=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Usando a árvore de decisão que foi montada automaticamente, jogue um jogo de \"adivinhar o número\". Quais números sáo mais difíceis de adivinhar, isto é, quais números precisam de mais perguntas para serem adivinhados?\n",
    "1. Como seria uma árvore de decisão para a estratégia de perguntar número por número?\n",
    "1. Qual é a propriedade da árvore que mede a \"dificuldade\" em encontrar um número?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 19\n",
    "*Objetivo: calcular a entropia para diferentes dados em jogos de RPG*\n",
    "\n",
    "Em jogos de RPG, particularmente Dungeons & Dragons, é comum usar dados diferentes do comum, de seis lados. O jogo usa dados de 4 faces, 6, 8, 10, 12 e 20 faces, e eles são referidos como d4, d6, d8, d10, d12 e d20:\n",
    "\n",
    "<img src=\"6dice(cropped).jpg\" height=300  />\n",
    "\n",
    "1. Calcule a entropia relacionada a jogar cada um desses dados, assumindo que são dados honestos (lembre-se de usar base 2!)\n",
    "1. Como a entropia do d4 se relaciona com a entropia da jogada da moeda? E a entropia do d8?\n",
    "1. Em um sistema digital, quantos bits são necessários para representar números que variam de 0 a 1? E de 0 a 3? E de 0 a 7?\n",
    "1. Quantas faces tem um dado cuja jogada tem uma entropia de 5 bits?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "N=2\n",
    "stats.entropy(np.ones(N)/N, base=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 20\n",
    "*Objetivo: relacionar a entropia à ideia de surpresa*\n",
    "\n",
    "Provavelmente, você teria mais \"surpresa\" com o resultado de um d20 (que pode ser qualquer uma das 20 possibilidades) que com o resultado de uma moeda (que só tem dois resultados possíveis). Escreva com suas palavras um parágrafo relacionando a entropia (que é uma característica mensurável) com a surpresa (que é uma sensação subjetiva)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aulas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
